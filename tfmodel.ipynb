{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers, optimizers, callbacks\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialDetectionModel:\n",
    "    def __init__(self, input_shape=(512,), num_classes=10, log_dir='./logs'):\n",
    "        \"\"\"\n",
    "        Initialize the facial detection model with TensorBoard logging\n",
    "        \n",
    "        Parameters:\n",
    "        - input_shape: Shape of the embedding input\n",
    "        - num_classes: Number of unique labels in the dataset\n",
    "        - log_dir: Directory for TensorBoard logs\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.log_dir = log_dir\n",
    "        \n",
    "        # Ensure log directory exists\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    def prepare_dataset(self, dataset):\n",
    "        \"\"\"\n",
    "        Prepare dataset for training\n",
    "        \n",
    "        Returns:\n",
    "        - X_train, y_train, X_test, y_test\n",
    "        \"\"\"\n",
    "        # Convert embeddings and labels to numpy arrays\n",
    "        X_train = np.array(dataset['train']['embedding'])\n",
    "        y_train = np.array(dataset['train']['label'])\n",
    "        X_test = np.array(dataset['test']['embedding'])\n",
    "        y_test = np.array(dataset['test']['label'])\n",
    "        \n",
    "        # One-hot encode labels\n",
    "        y_train = tf.keras.utils.to_categorical(y_train, num_classes=self.num_classes)\n",
    "        y_test = tf.keras.utils.to_categorical(y_test, num_classes=self.num_classes)\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    def build_model(self,learning_rate=1e-3):\n",
    "        \"\"\"\n",
    "        Build a neural network for classification\n",
    "        \"\"\"\n",
    "        self.model = models.Sequential([\n",
    "            layers.Input(shape=self.input_shape),\n",
    "            # First dense layer with L2 regularization and dropout\n",
    "            layers.Dense(264, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "            layers.Dropout(0.4),\n",
    "\n",
    "            # Second dense layer\n",
    "            layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "            layers.Dropout(0.4),\n",
    "\n",
    "            # Third dense layer\n",
    "            layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Advanced optimizer with adaptive learning rate\n",
    "        optimizer = optimizers.Adam(\n",
    "            learning_rate=learning_rate, \n",
    "            clipnorm=1.0  # Gradient clipping to prevent exploding gradients\n",
    "        )\n",
    "\n",
    "        # Compile with advanced metrics\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[\n",
    "                'accuracy',\n",
    "                tf.keras.metrics.Precision(),\n",
    "                tf.keras.metrics.Recall(),\n",
    "                tf.keras.metrics.AUC()\n",
    "            ]\n",
    "        )\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    def train(self, dataset, epochs=100, batch_size=8):\n",
    "        \"\"\"\n",
    "        Train the model with TensorBoard logging\n",
    "        \n",
    "        Returns:\n",
    "        - Training history\n",
    "        \"\"\"\n",
    "        # Prepare dataset\n",
    "        X_train, y_train, X_test, y_test = self.prepare_dataset(dataset)\n",
    "        \n",
    "        # Build model if not already built\n",
    "        if self.model is None:\n",
    "            self.build_model()\n",
    "        \n",
    "        # Callbacks for advanced training\n",
    "        callbacks_list = [\n",
    "            \n",
    "            # Early stopping to prevent overfitting\n",
    "            callbacks.EarlyStopping(\n",
    "                monitor='val_loss', \n",
    "                patience=10, \n",
    "                restore_best_weights=True\n",
    "            ), \n",
    "            # Reduce learning rate when plateau occurs\n",
    "            callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss', \n",
    "                factor=0.5, \n",
    "                patience=5, \n",
    "                min_lr=1e-5\n",
    "            ),\n",
    "            \n",
    "            # TensorBoard for visualization\n",
    "            callbacks.TensorBoard(\n",
    "                log_dir=self.log_dir, \n",
    "                histogram_freq=1,\n",
    "                profile_batch=0\n",
    "            ),\n",
    "            \n",
    "            # Model checkpointing\n",
    "            callbacks.ModelCheckpoint(\n",
    "                filepath=os.path.join(self.log_dir, 'best_model.keras'),\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        # Train the model with callbacks\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def plot_training_history(self, history):\n",
    "        \"\"\"\n",
    "        Create comprehensive plots of training history\n",
    "        \n",
    "        Parameters:\n",
    "        - history: Model training history\n",
    "        \"\"\"\n",
    "        # Create a figure with multiple subplots\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Plot training & validation accuracy values\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "        \n",
    "        # Plot training & validation loss values\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def run_tensorboard(self):\n",
    "        \"\"\"\n",
    "        Start TensorBoard server\n",
    "        \n",
    "        Note: Run this in a separate terminal or notebook cell\n",
    "        \"\"\"\n",
    "        import subprocess\n",
    "        \n",
    "        # Start TensorBoard\n",
    "        tensorboard_process = subprocess.Popen(\n",
    "            ['tensorboard', '--logdir', self.log_dir]\n",
    "        )\n",
    "        print(f\"TensorBoard running. Open http://localhost:6006 in your browser.\")\n",
    "        return tensorboard_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551b9925a4c048678f46d65db3cb8348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821f6434186945de8dec6c4ba32cceb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/20.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7952dbaeee48e08136a38a1a95b324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/9.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d56d78262a484dbf92ae36c92c6129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3586 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dba513aa80542af8a06d9e154fd73a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Assuming you've already loaded your dataset\n",
    "dataset = load_dataset(\"Tarakeshwaran/sampleface30-Dataset\")  # Your dataset loading code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['embedding', 'label'],\n",
       "        num_rows: 3586\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['embedding', 'label'],\n",
       "        num_rows: 1538\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 264)               338184    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 264)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 128)               33920     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 31)                2015      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 382375 (1.46 MB)\n",
      "Trainable params: 382375 (1.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "449/449 [==============================] - 5s 7ms/step - loss: 3.0869 - accuracy: 0.1071 - precision_9: 0.5873 - recall_9: 0.0103 - auc_9: 0.7574 - val_loss: 2.5609 - val_accuracy: 0.2029 - val_precision_9: 0.8947 - val_recall_9: 0.0442 - val_auc_9: 0.8721 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 2.6058 - accuracy: 0.1969 - precision_9: 0.6431 - recall_9: 0.0482 - auc_9: 0.8592 - val_loss: 2.2400 - val_accuracy: 0.3121 - val_precision_9: 0.8911 - val_recall_9: 0.0585 - val_auc_9: 0.9199 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 2.3178 - accuracy: 0.2724 - precision_9: 0.6582 - recall_9: 0.0864 - auc_9: 0.8974 - val_loss: 1.9389 - val_accuracy: 0.4122 - val_precision_9: 0.8916 - val_recall_9: 0.0962 - val_auc_9: 0.9419 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 2.0498 - accuracy: 0.3528 - precision_9: 0.6662 - recall_9: 0.1481 - auc_9: 0.9245 - val_loss: 1.7720 - val_accuracy: 0.4538 - val_precision_9: 0.7973 - val_recall_9: 0.1508 - val_auc_9: 0.9508 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.9125 - accuracy: 0.4083 - precision_9: 0.6702 - recall_9: 0.1938 - auc_9: 0.9350 - val_loss: 1.6631 - val_accuracy: 0.5000 - val_precision_9: 0.7834 - val_recall_9: 0.1905 - val_auc_9: 0.9587 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.7037 - accuracy: 0.4685 - precision_9: 0.7063 - recall_9: 0.2736 - auc_9: 0.9503 - val_loss: 1.5658 - val_accuracy: 0.5241 - val_precision_9: 0.8119 - val_recall_9: 0.2581 - val_auc_9: 0.9636 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.6205 - accuracy: 0.4975 - precision_9: 0.7351 - recall_9: 0.3243 - auc_9: 0.9551 - val_loss: 1.5303 - val_accuracy: 0.5455 - val_precision_9: 0.8262 - val_recall_9: 0.3121 - val_auc_9: 0.9639 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.5013 - accuracy: 0.5569 - precision_9: 0.7484 - recall_9: 0.3823 - auc_9: 0.9613 - val_loss: 1.4117 - val_accuracy: 0.5793 - val_precision_9: 0.8182 - val_recall_9: 0.3570 - val_auc_9: 0.9700 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.4031 - accuracy: 0.5823 - precision_9: 0.7604 - recall_9: 0.4186 - auc_9: 0.9680 - val_loss: 1.3955 - val_accuracy: 0.5878 - val_precision_9: 0.7980 - val_recall_9: 0.4109 - val_auc_9: 0.9664 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.3235 - accuracy: 0.6129 - precision_9: 0.7700 - recall_9: 0.4621 - auc_9: 0.9718 - val_loss: 1.3907 - val_accuracy: 0.5884 - val_precision_9: 0.7566 - val_recall_9: 0.4467 - val_auc_9: 0.9682 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.2127 - accuracy: 0.6550 - precision_9: 0.7897 - recall_9: 0.5298 - auc_9: 0.9758 - val_loss: 1.2803 - val_accuracy: 0.6437 - val_precision_9: 0.7773 - val_recall_9: 0.4993 - val_auc_9: 0.9736 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.1787 - accuracy: 0.6695 - precision_9: 0.7923 - recall_9: 0.5605 - auc_9: 0.9780 - val_loss: 1.2587 - val_accuracy: 0.6606 - val_precision_9: 0.8062 - val_recall_9: 0.5221 - val_auc_9: 0.9727 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.1124 - accuracy: 0.6949 - precision_9: 0.8067 - recall_9: 0.5923 - auc_9: 0.9803 - val_loss: 1.2894 - val_accuracy: 0.6580 - val_precision_9: 0.7666 - val_recall_9: 0.5553 - val_auc_9: 0.9703 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.0867 - accuracy: 0.7103 - precision_9: 0.8080 - recall_9: 0.6171 - auc_9: 0.9810 - val_loss: 1.2336 - val_accuracy: 0.6651 - val_precision_9: 0.8137 - val_recall_9: 0.5566 - val_auc_9: 0.9758 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 1.0525 - accuracy: 0.7303 - precision_9: 0.8262 - recall_9: 0.6431 - auc_9: 0.9805 - val_loss: 1.2278 - val_accuracy: 0.6658 - val_precision_9: 0.7787 - val_recall_9: 0.5650 - val_auc_9: 0.9758 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.9689 - accuracy: 0.7549 - precision_9: 0.8343 - recall_9: 0.6765 - auc_9: 0.9852 - val_loss: 1.2123 - val_accuracy: 0.6834 - val_precision_9: 0.7758 - val_recall_9: 0.6099 - val_auc_9: 0.9744 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.9732 - accuracy: 0.7540 - precision_9: 0.8291 - recall_9: 0.6860 - auc_9: 0.9837 - val_loss: 1.2567 - val_accuracy: 0.6899 - val_precision_9: 0.7897 - val_recall_9: 0.6079 - val_auc_9: 0.9712 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.9473 - accuracy: 0.7758 - precision_9: 0.8416 - recall_9: 0.7114 - auc_9: 0.9841 - val_loss: 1.2051 - val_accuracy: 0.7087 - val_precision_9: 0.7898 - val_recall_9: 0.6255 - val_auc_9: 0.9716 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.9056 - accuracy: 0.7875 - precision_9: 0.8548 - recall_9: 0.7242 - auc_9: 0.9861 - val_loss: 1.2411 - val_accuracy: 0.7178 - val_precision_9: 0.8010 - val_recall_9: 0.6411 - val_auc_9: 0.9688 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.9096 - accuracy: 0.7953 - precision_9: 0.8529 - recall_9: 0.7340 - auc_9: 0.9851 - val_loss: 1.2133 - val_accuracy: 0.7165 - val_precision_9: 0.8044 - val_recall_9: 0.6632 - val_auc_9: 0.9711 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.8763 - accuracy: 0.7981 - precision_9: 0.8606 - recall_9: 0.7418 - auc_9: 0.9869 - val_loss: 1.2585 - val_accuracy: 0.7289 - val_precision_9: 0.8046 - val_recall_9: 0.6612 - val_auc_9: 0.9672 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.8418 - accuracy: 0.8112 - precision_9: 0.8631 - recall_9: 0.7663 - auc_9: 0.9873 - val_loss: 1.2484 - val_accuracy: 0.7250 - val_precision_9: 0.7880 - val_recall_9: 0.6671 - val_auc_9: 0.9668 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.8502 - accuracy: 0.8218 - precision_9: 0.8708 - recall_9: 0.7669 - auc_9: 0.9876 - val_loss: 1.2887 - val_accuracy: 0.7224 - val_precision_9: 0.7817 - val_recall_9: 0.6658 - val_auc_9: 0.9652 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.6863 - accuracy: 0.8639 - precision_9: 0.9086 - recall_9: 0.8232 - auc_9: 0.9924 - val_loss: 1.1922 - val_accuracy: 0.7536 - val_precision_9: 0.8214 - val_recall_9: 0.7178 - val_auc_9: 0.9675 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.6796 - accuracy: 0.8689 - precision_9: 0.9081 - recall_9: 0.8427 - auc_9: 0.9911 - val_loss: 1.1723 - val_accuracy: 0.7679 - val_precision_9: 0.8186 - val_recall_9: 0.7308 - val_auc_9: 0.9668 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.6214 - accuracy: 0.8823 - precision_9: 0.9146 - recall_9: 0.8511 - auc_9: 0.9933 - val_loss: 1.1924 - val_accuracy: 0.7718 - val_precision_9: 0.8184 - val_recall_9: 0.7269 - val_auc_9: 0.9678 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.6188 - accuracy: 0.8901 - precision_9: 0.9168 - recall_9: 0.8606 - auc_9: 0.9927 - val_loss: 1.1493 - val_accuracy: 0.7698 - val_precision_9: 0.8111 - val_recall_9: 0.7341 - val_auc_9: 0.9681 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "449/449 [==============================] - 3s 7ms/step - loss: 0.6007 - accuracy: 0.8898 - precision_9: 0.9138 - recall_9: 0.8661 - auc_9: 0.9930 - val_loss: 1.1884 - val_accuracy: 0.7718 - val_precision_9: 0.8157 - val_recall_9: 0.7425 - val_auc_9: 0.9665 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.5637 - accuracy: 0.8957 - precision_9: 0.9215 - recall_9: 0.8675 - auc_9: 0.9952 - val_loss: 1.2522 - val_accuracy: 0.7588 - val_precision_9: 0.8050 - val_recall_9: 0.7302 - val_auc_9: 0.9635 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.5700 - accuracy: 0.9018 - precision_9: 0.9252 - recall_9: 0.8765 - auc_9: 0.9932 - val_loss: 1.1969 - val_accuracy: 0.7776 - val_precision_9: 0.8136 - val_recall_9: 0.7523 - val_auc_9: 0.9662 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.5588 - accuracy: 0.8940 - precision_9: 0.9184 - recall_9: 0.8723 - auc_9: 0.9934 - val_loss: 1.1706 - val_accuracy: 0.7744 - val_precision_9: 0.8233 - val_recall_9: 0.7484 - val_auc_9: 0.9663 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.5181 - accuracy: 0.9074 - precision_9: 0.9346 - recall_9: 0.8851 - auc_9: 0.9950 - val_loss: 1.1537 - val_accuracy: 0.7763 - val_precision_9: 0.8125 - val_recall_9: 0.7581 - val_auc_9: 0.9663 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.4710 - accuracy: 0.9233 - precision_9: 0.9429 - recall_9: 0.9018 - auc_9: 0.9968 - val_loss: 1.1913 - val_accuracy: 0.7952 - val_precision_9: 0.8227 - val_recall_9: 0.7724 - val_auc_9: 0.9636 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.4420 - accuracy: 0.9353 - precision_9: 0.9514 - recall_9: 0.9225 - auc_9: 0.9959 - val_loss: 1.2301 - val_accuracy: 0.7893 - val_precision_9: 0.8151 - val_recall_9: 0.7737 - val_auc_9: 0.9610 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.4469 - accuracy: 0.9322 - precision_9: 0.9460 - recall_9: 0.9183 - auc_9: 0.9960 - val_loss: 1.1789 - val_accuracy: 0.7919 - val_precision_9: 0.8203 - val_recall_9: 0.7718 - val_auc_9: 0.9660 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.4483 - accuracy: 0.9281 - precision_9: 0.9460 - recall_9: 0.9136 - auc_9: 0.9966 - val_loss: 1.2009 - val_accuracy: 0.7945 - val_precision_9: 0.8208 - val_recall_9: 0.7744 - val_auc_9: 0.9630 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.4259 - accuracy: 0.9398 - precision_9: 0.9518 - recall_9: 0.9255 - auc_9: 0.9958 - val_loss: 1.2042 - val_accuracy: 0.7919 - val_precision_9: 0.8177 - val_recall_9: 0.7757 - val_auc_9: 0.9634 - lr: 2.5000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Convert to TFLite\\nfacial_model.convert_to_tflite()\\n\\n# Optional: Evaluate the model\\nfacial_model.evaluate(dataset)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "facial_model = FacialDetectionModel(\n",
    "    input_shape=(len(dataset['train'][0]['embedding']),),\n",
    "    num_classes=len(set(dataset['train']['label']))\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = facial_model.train(dataset)\n",
    "\n",
    "# Plot training history\n",
    "facial_model.plot_training_history(history)\n",
    "\"\"\"\n",
    "# Convert to TFLite\n",
    "facial_model.convert_to_tflite()\n",
    "\n",
    "# Optional: Evaluate the model\n",
    "facial_model.evaluate(dataset)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
