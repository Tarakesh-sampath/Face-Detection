{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe file 'venv\\lib\\site-packages\\typing_extensions.py' seems to be overriding built in modules and interfering with the startup of the kernel. Consider renaming the file and starting the kernel again.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresOverridingBuiltInModules'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "!pip3 install \"tensorflow<2.11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the installation:\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import os\n",
    "\n",
    "class EfficientFaceMatcher:\n",
    "    def __init__(self, dataset_path):\n",
    "        # Load dataset\n",
    "        self.dataset = pd.read_csv(dataset_path)\n",
    "        \n",
    "        # Extract embeddings for all images\n",
    "        self.database_embeddings = self._extract_all_embeddings()\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        self.database_embeddings = self._normalize_embeddings(self.database_embeddings)\n",
    "        \n",
    "        # Create FAISS index\n",
    "        dimension = self.database_embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(dimension)\n",
    "        self.index.add(self.database_embeddings)\n",
    "    \n",
    "    def _extract_all_embeddings(self):\n",
    "        \"\"\"\n",
    "        Extract embeddings for all images in the dataset\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Array of embeddings for all images\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        for img_path in self.dataset['image_location']:\n",
    "            try:\n",
    "                # Ensure the image path exists\n",
    "                if not os.path.exists(img_path):\n",
    "                    print(f\"Warning: Image not found {img_path}\")\n",
    "                    # Append a zero vector for missing images\n",
    "                    embeddings.append(np.zeros(512))\n",
    "                    continue\n",
    "                \n",
    "                # Extract embedding\n",
    "                embedding = self._extract_single_embedding(img_path)\n",
    "                embeddings.append(embedding)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "                # Append a zero vector for failed extractions\n",
    "                embeddings.append(np.zeros(512))\n",
    "        \n",
    "        return np.array(embeddings)\n",
    "    \n",
    "    def _extract_single_embedding(self, image_path):\n",
    "        \"\"\"Extract embedding for a single image\"\"\"\n",
    "        img = image.load_img(image_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        \n",
    "        # Use VGG16 as a feature extractor (replace with a dedicated face embedding model in practice)\n",
    "        model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "        embedding = model.predict(x)\n",
    "        return embedding.flatten()\n",
    "    \n",
    "    def _normalize_embeddings(self, embeddings):\n",
    "        \"\"\"Normalize embeddings to unit length for cosine similarity\"\"\"\n",
    "        norms = np.linalg.norm(embeddings, axis=1)\n",
    "        return embeddings / norms[:, np.newaxis]\n",
    "    \n",
    "    def find_match(self, query_image_path, threshold=0.7):\n",
    "        \"\"\"\n",
    "        Find potential matches for a query image\n",
    "        \n",
    "        Args:\n",
    "            query_image_path (str): Path to the query image\n",
    "            threshold (float): Similarity threshold for match\n",
    "        \n",
    "        Returns:\n",
    "            dict: Matching results with similarity scores and tags\n",
    "        \"\"\"\n",
    "        # Extract query embedding\n",
    "        query_embedding = self._extract_single_embedding(query_image_path)\n",
    "        query_embedding = self._normalize_embeddings(np.array([query_embedding]))\n",
    "        \n",
    "        # Perform similarity search\n",
    "        distances, indices = self.index.search(query_embedding, k=5)\n",
    "        \n",
    "        # Process results\n",
    "        matches = []\n",
    "        for dist, idx in zip(distances[0], indices[0]):\n",
    "            if dist >= threshold:\n",
    "                # Get additional information from the original dataset\n",
    "                match_info = self.dataset.iloc[idx]\n",
    "                matches.append({\n",
    "                    'index': int(idx),\n",
    "                    'similarity': float(dist),\n",
    "                    'image_location': match_info['image_location'],\n",
    "                    'tags': match_info['tags'] if 'tags' in self.dataset.columns else None\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'has_match': len(matches) > 0,\n",
    "            'matches': matches\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Path to your CSV file\n",
    "    dataset_path = 'dataset.csv'\n",
    "    \n",
    "    # Expected CSV format:\n",
    "    # image_location,tags\n",
    "    # /path/to/image1.jpg,person1,outdoor\n",
    "    # /path/to/image2.jpg,person2,indoor\n",
    "    \n",
    "    # Initialize matcher\n",
    "    matcher = EfficientFaceMatcher(dataset_path)\n",
    "    \n",
    "    # Example: Match a query image\n",
    "    query_image_path = 'query_image.jpg'\n",
    "    result = matcher.find_match(query_image_path)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Matching Results:\")\n",
    "    if result['has_match']:\n",
    "        for match in result['matches']:\n",
    "            print(f\"Match Found:\")\n",
    "            print(f\"  Similarity: {match['similarity']}\")\n",
    "            print(f\"  Image Location: {match['image_location']}\")\n",
    "            print(f\"  Tags: {match['tags']}\")\n",
    "    else:\n",
    "        print(\"No matches found.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
